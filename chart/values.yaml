tags:
  # Controls whether Prometheus and Grafana should be be installed as part of
  # this meta Helm chart. The chart is configured to use them if they are
  # available. Its also worth noting that access to Grafana relies on
  # JupyterHub's configurable proxy in this setup, so JupyterHub needs to run to
  # be able to access Grafana.
  metrics: false
  dask-gateway: false

nfs:
  enabled: false

daskhub:
  jupyterhub:
    hub:
      extraConfig:
        # Copy of https://github.com/dask/helm-chart/blob/b819b2a61202f7b168b376b8ce30cfcdf2f9359e/daskhub/values.yaml#L12-L51
        00-add-dask-gateway-values: |
          # 1. Sets `DASK_GATEWAY__PROXY_ADDRESS` in the singleuser environment.
          # 2. Adds the URL for the Dask Gateway JupyterHub service.
          import os
          # These are set by jupyterhub.
          release_name = os.environ["HELM_RELEASE_NAME"]
          release_namespace = os.environ["POD_NAMESPACE"]
          if "PROXY_HTTP_SERVICE_HOST" in os.environ:
              # https is enabled, we want to use the internal http service.
              gateway_address = "http://{}:{}/services/dask-gateway/".format(
                  os.environ["PROXY_HTTP_SERVICE_HOST"],
                  os.environ["PROXY_HTTP_SERVICE_PORT"],
              )
              print("Setting DASK_GATEWAY__ADDRESS {} from HTTP service".format(gateway_address))
          else:
              gateway_address = "http://proxy-public/services/dask-gateway"
              print("Setting DASK_GATEWAY__ADDRESS {}".format(gateway_address))
          # Internal address to connect to the Dask Gateway.
          c.KubeSpawner.environment.setdefault("DASK_GATEWAY__ADDRESS", gateway_address)
          # Internal address for the Dask Gateway proxy.
          c.KubeSpawner.environment.setdefault("DASK_GATEWAY__PROXY_ADDRESS", "gateway://traefik-{}-dask-gateway.{}:80".format(release_name, release_namespace))
          # Relative address for the dashboard link.
          c.KubeSpawner.environment.setdefault("DASK_GATEWAY__PUBLIC_ADDRESS", "/services/dask-gateway/")
          # Use JupyterHub to authenticate with Dask Gateway.
          c.KubeSpawner.environment.setdefault("DASK_GATEWAY__AUTH__TYPE", "jupyterhub")
          # Adds Dask Gateway as a JupyterHub service to make the gateway available at
          # {HUB_URL}/services/dask-gateway
          service_url = "http://traefik-{}-dask-gateway.{}".format(release_name, release_namespace)
          for service in c.JupyterHub.services:
              if service["name"] == "dask-gateway":
                  if not service.get("url", None):
                      print("Adding dask-gateway service URL")
                      service.setdefault("url", service_url)
                  break
          else:
              print("dask-gateway service not found. Did you set jupyterhub.hub.services.dask-gateway.apiToken?")

      # Disabled because of dask-gateway Helm chart 0.9.0 requires a fix before it
      # works: https://github.com/dask/dask-gateway/pull/352
      networkPolicy:
        enabled: false

      # NOTE: readinessProbe is disabled because of bad default values make a hub
      # under load become unavailable.
      #
      # ref: https://github.com/jupyterhub/zero-to-jupyterhub-k8s/issues/1732
      readinessProbe:
        enabled: false

      # ref: https://jupyterhub.readthedocs.io/en/stable/reference/services.html#properties-of-a-service
      services:
        grafana:
          # This will make the CHP proxy let /services/grafana route to the
          # grafana service in the k8s namespace, which lets us make use of
          # JupyterHub's HTTPS setup without needing something like nginx-ingress
          # + cert-manager and additional ingress k8s resources.
          url: http://grafana

      resources:
        requests:
          cpu: 50m
          memory: 1Gi
        limits:
          cpu: 1000m
          memory: 1Gi

    proxy:
      chp:
        resources:
          requests:
            memory: 320Mi
            cpu: 50m
          limits:
            memory: 320Mi
            cpu: 500m
      traefik:
        resources:
          requests:
            memory: 512Mi
            cpu: 50m
          limits:
            memory: 512Mi
            cpu: 1000m

  # Reference on the configuration options:
  # https://github.com/dask/dask-gateway/blob/master/resources/helm/dask-gateway/values.yaml
  dask-gateway:
    gateway:
      prefix: "/services/dask-gateway"  # Connect to Dask-Gateway through a JupyterHub service.
      auth:
        type: jupyterhub  # Use JupyterHub to authenticate with Dask-Gateway
      backend:
        scheduler:
          extraPodConfig:
            nodeSelector:
              hub.jupyter.org/node-purpose: user
            tolerations:
              - effect: NoSchedule
                key: hub.jupyter.org_dedicated
                operator: Equal
                value: user
        worker:
          extraPodConfig:
            nodeSelector:
              worker: "true"
            tolerations:
              - effect: NoSchedule
                key: worker
                operator: Equal
                value: "true"
    traefik:
      service:
        type: ClusterIP  # Access Dask-Gateway through JupyterHub.


# Reference on the configuration options:
# https://github.com/helm/charts/blob/master/stable/grafana/values.yaml
grafana:
  fullnameOverride: grafana
  adminUser: admin

  # NOTE: It can be useful to be able to render an image of a chart, but that
  #       requires a workaround configuration of the Grafana Helm chart at the
  #       moment.
  #
  #       workaround: https://github.com/helm/charts/issues/21959#issuecomment-640653320
  #       issue with workaround: https://github.com/grafana/grafana/issues/25716
  extraContainers: |
    - name: renderer
      image: grafana/grafana-image-renderer:latest
      resources:
        requests:
          memory: 128Mi
          cpu: 10m
        limits:
          memory: 512Mi
          cpu: 250m
  env:
    GF_RENDERING_SERVER_URL: http://localhost:8081/render
    GF_RENDERING_CALLBACK_URL: http://localhost:3000/services/grafana

  # NOTE: We need Recreate when using a persistence PVC. If we use an external
  # database, we can do a RollingUpdate instead.
  deploymentStrategy:
    type: Recreate

  persistence:
    type: pvc
    enabled: true

  service:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/path: "/services/grafana/metrics"

  resources:
    limits:
      cpu: 1
      memory: 1Gi
    requests:
      cpu: 50m
      memory: 100Mi

  initChownData:
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 25m
        memory: 64Mi


# Reference on the configuration options:
# https://github.com/helm/charts/blob/master/stable/prometheus/values.yaml
prometheus:
  fullnameOverride: prometheus

  # the actual prometheus server that polls various sources for metrics etc.
  server:
    fullnameOverride: prometheus-server
    enabled: true

    # data retention period
    retention: 3y

    # NOTE: We prefer StatefulSet to be used when using a persistence PVC. If we
    #       use an external database, we can use a Deployment with rolling
    #       updates instead. Until then, we should shut down one pod and then
    #       start up another, which a StatefulSet will do by default and a
    #       Deployment will Recreate as an upgradeStrategy will also do.
    statefulSet:
      enabled: true
    persistentVolume:
      enabled: true
      size: 200Gi
    resources:
      limits:
        cpu: 2
        memory: 12Gi
      requests:
        cpu: 50m
        # IMPORTANT: This value was lowered to 100Mi from 12Gi after the course
        # ended to allow prometheus to run in a cheaper node.
        memory: 100Mi

  # alertmanager is meant to be able to alert using email etc. Grafana can also
  # do this by itself to some degree at least as I understand it.
  alertmanager:
    fullnameOverride: prometheus-alertmanager
    enabled: false

  # kube-state-metrics exports information coming from the kubernetes api-server
  # about the state of kubernetes resources. It can list the state of pods etc.
  #
  # ref: https://github.com/helm/charts/blob/master/stable/prometheus/requirements.yaml
  # ref: https://github.com/helm/charts/tree/master/stable/kube-state-metrics
  kube-state-metrics:
    fullnameOverride: prometheus-kube-state-metrics
    resources:
      limits:
        cpu: 100m
        memory: 64Mi
      requests:
        cpu: 10m
        memory: 32Mi
  kubeStateMetrics:
    enabled: true

  nodeExporter:
    fullnameOverride: prometheus-node-exporter
    enabled: true
    # NOTE: We want to be able to scrape metrics on all nodes, even GPU nodes
    #       etc.
    tolerations:
      - operator: "Exists"
    resources:
      limits:
        cpu: 200m
        memory: 50Mi
      requests:
        cpu: 50m
        memory: 30Mi

  # pushgateway is meant to buffer metrics pushed to it from short lived sources
  # and expose them later for prometheus in their place.
  pushgateway:
    fullnameOverride: prometheus-pushgateway
    enabled: false
